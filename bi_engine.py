import os
import json
import hashlib
from typing import List, Dict, Any, Optional
from dotenv import load_dotenv
from langchain_neo4j import Neo4jGraph
from langchain_openai import AzureChatOpenAI

load_dotenv()

class BusinessIntelligenceEngine:
    """
    GraphRAG-based Business Intelligence Engine for TalentMatch.
    Configured for Azure OpenAI (PJATK Environment).
    
    Includes:
    - GDPR/Privacy Compliance
    - Strict Business Logic (Bench vs Capacity)
    - Hybrid Temperature Strategy
    """

    def __init__(self):
        # 1. Konfiguracja Neo4j
        self.graph = Neo4jGraph(
            url=os.getenv("NEO4J_URI", "bolt://127.0.0.1:7687"),
            username=os.getenv("NEO4J_USERNAME", "neo4j"),
            password=os.getenv("NEO4J_PASSWORD", "password123")
        )

        # 2. LLM LOGICZNY (Temperature=1 dla o1/reasoning)
        self.llm_logic = AzureChatOpenAI(
            azure_deployment=os.getenv("AZURE_DEPLOYMENT_NAME"),
            api_version=os.getenv("OPENAI_API_VERSION"),
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
            api_key=os.getenv("AZURE_OPENAI_API_KEY"),
            temperature=1 
        )

        # 3. LLM KREATYWNY
        self.llm_creative = AzureChatOpenAI(
            azure_deployment=os.getenv("AZURE_DEPLOYMENT_NAME"),
            api_version=os.getenv("OPENAI_API_VERSION"),
            azure_endpoint=os.getenv("AZURE_OPENAI_ENDPOINT"),
            api_key=os.getenv("AZURE_OPENAI_API_KEY"),
            temperature=1 
        )

    # ==================== PRIVACY & SECURITY LAYER (RODO/GDPR) ====================

    def _anonymize_data(self, data_list: List[Dict]) -> tuple[List[Dict], Dict]:
        """
        üõ°Ô∏è AGRESYWNA BRAMA PRYWATNO≈öCI:
        Maskuje ka≈ºde pole, kt√≥re wyglƒÖda na imiƒô i nazwisko lub zawiera wra≈ºliwe s≈Çowa,
        niezale≈ºnie od nazwy kolumny (obs≈Çuguje p.name, developer, person_A itp.)
        """
        if not isinstance(data_list, list):
            return data_list, {}

        anonymized_list = []
        decoder_map = {}
        
        # S≈Çowa kluczowe, kt√≥rych wystƒÖpienie w nazwie kolumny wymusza maskowanie
        sensitive_keywords = [
            'name', 'developer', 'person', 'id', 'user', 
            'collaborator', 'focus', 'candidate', 'member'
        ]

        for item in data_list:
            if not isinstance(item, dict):
                anonymized_list.append(item)
                continue

            safe_item = item.copy()
            
            for field, value in safe_item.items():
                if not value or not isinstance(value, str):
                    continue
                
                val_str = value.strip()
                field_lower = field.lower()
                
                # 1. Sprawd≈∫, czy nazwa kolumny zawiera wra≈ºliwe s≈Çowo (np. "p.name")
                is_sensitive_field = any(sk in field_lower for sk in sensitive_keywords)
                
                # 2. Sprawd≈∫ semantycznie, czy tre≈õƒá wyglƒÖda na Imiƒô i Nazwisko:
                # - Minimum dwa wyrazy
                # - Wyrazy zaczynajƒÖ siƒô z wielkiej litery
                # - Brak cyfr i znak√≥w specjalnych
                words = val_str.split()
                looks_like_name = (
                    len(words) >= 2 and 
                    all(word[0].isupper() for word in words if word) and
                    val_str.replace(" ", "").replace("-", "").isalpha()
                )

                if is_sensitive_field or looks_like_name:
                    # Stabilny mapping: ta sama osoba zawsze dostaje ten sam Candidate_ID
                    if val_str not in decoder_map.values():
                        hash_suffix = hashlib.md5(val_str.encode()).hexdigest()[:6].upper()
                        fake_id = f"Candidate_{hash_suffix}"
                        decoder_map[fake_id] = val_str
                    else:
                        fake_id = [k for k, v in decoder_map.items() if v == val_str][0]
                    
                    safe_item[field] = fake_id
            
            anonymized_list.append(safe_item)
            
        return anonymized_list, decoder_map

    # ==================== UTILS ====================

    def classify_query(self, question: str) -> str:
        """Classify the query into one of 6 types."""
        prompt = f"""
        Classify this business intelligence query into ONE of these categories:

        1. COUNTING - "how many", "count"
        2. FILTERING - "find developers", "list people", "what skills", "who knows"
        3. AGGREGATION - "average", "total", "sum", "stats"
        4. REASONING - "worked together", "same university", "relationships"
        5. TEMPORAL - "available", "when", "dates", "schedule", "free now", "who is free"
        6. SCENARIO - "optimal team", "gap analysis", "what if", "suggest a team"

        Query: {question}

        Respond with ONLY the category name.
        """
        try:
            response = self.llm_logic.invoke(prompt)
            category = response.content.strip().upper()
            mapping = {
                'COUNTING': 'counting', 'FILTERING': 'filtering',
                'AGGREGATION': 'aggregation', 'REASONING': 'reasoning',
                'TEMPORAL': 'temporal', 'SCENARIO': 'scenario'
            }
            for key, val in mapping.items():
                if key in category:
                    return val
            return 'scenario'
        except Exception as e:
            print(f"‚ö†Ô∏è Error classifying query: {e}")
            return 'scenario'

    def extract_json_from_response(self, text: str) -> Optional[Dict]:
        try:
            start = text.find('{')
            end = text.rfind('}') + 1
            if start == -1 or end == 0: return None
            return json.loads(text[start:end])
        except:
            return None

    # ==================== QUERY HANDLERS ====================

    def handle_counting_query(self, question: str) -> Dict[str, Any]:
        print(f"üî¢ COUNTING QUERY: {question}")
        
        # 1. Logika: Dostƒôpni (Spare Capacity)
        if 'available' in question.lower() and ('how many' in question.lower() or 'count' in question.lower()):
            cypher = """
            MATCH (p:Person)
            OPTIONAL MATCH (p)-[r:ASSIGNED_TO]->()
            WITH p, sum(CASE WHEN r.allocation IS NOT NULL THEN r.allocation ELSE 0.0 END) as current_load
            WHERE current_load < 1.0
            RETURN count(p) as result
            """
        # 2. Logika: Zliczanie po skillach (Fix dla Scenariusza 5)
        elif 'security' in question.lower() and 'count' in question.lower():
             cypher = """
             MATCH (p:Person)-[:HAS_SKILL]->(s:Skill)
             WHERE toLower(s.id) CONTAINS 'security' OR toLower(s.name) CONTAINS 'security'
             RETURN count(DISTINCT p) as result
             """
        # 3. Logika: Bench (Totalnie wolni)
        elif 'bench' in question.lower() or 'not assigned' in question.lower():
            cypher = """
            MATCH (p:Person)
            WHERE NOT (p)-[:ASSIGNED_TO]->(:Project)
            RETURN count(p) as result
            """
        # 4. Fallback - generowany Cypher
        else:
            cypher = f"MATCH (n:Person) RETURN count(n) as result"

        try:
            result = self.graph.query(cypher)
            count = result[0]['result'] if result else 0
            return {'type': 'counting', 'result': count, 'cypher': cypher, 'success': True}
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def handle_filtering_query(self, question: str) -> Dict[str, Any]:
        print(f"üîç FILTERING QUERY: {question}")
        
        # WyciƒÖgamy s≈Çowo kluczowe (np. 'AWS')
        keyword = question.split()[-1] if " " in question else "Python"
        if "AWS" in question: keyword = "AWS"
        
        cypher_generation_prompt = f"""
        Task: Generate Neo4j Cypher query for: "{question}"
        
        Schema: 
        - (:Person {{name, role, seniority, rate}})
        - (:Skill {{id}}) 
        - (:Project {{name, status}})
        - Rel: (:Person)-[:HAS_SKILL]->(:Skill), (:Person)-[:ASSIGNED_TO]->(:Project)
        
        CRITICAL RULES:
        1. Use CONTAINS for string matching (toLower(s.id) CONTAINS 'python').
        2. Return columns: p.name, p.role, p.seniority, collect(s.id) as skills.
        3. LIMIT 20.
        4. **DO NOT use 'p.status'**. Availability is calculated via relationships, not a property.
        5. Output ONLY the query, no markdown.
        """
        try:
            resp = self.llm_logic.invoke(cypher_generation_prompt)
            cypher = resp.content.replace('```cypher','').replace('```','').strip()
            
            # --- ZMIANA: Bezpiecznik na wypadek halucynacji ---
            if "p.status" in cypher:
                 print("‚ö†Ô∏è Detected risky query (status on Person). Using fallback.")
                 cypher = f"MATCH (p:Person)-[:HAS_SKILL]->(s:Skill) WHERE toLower(s.id) CONTAINS toLower('{keyword}') RETURN p.name, p.role LIMIT 10"

            results = self.graph.query(cypher)
            return {'type': 'filtering', 'result': results, 'cypher': cypher, 'success': True}
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def handle_aggregation_query(self, question: str) -> Dict[str, Any]:
        print(f"üìä AGGREGATION QUERY: {question}")

        if 'average' in question.lower() and 'experience' in question.lower():
            cypher = """
            MATCH (p:Person)
            WHERE p.years_of_experience IS NOT NULL
            RETURN 
                count(p) as total_developers,
                round(avg(p.years_of_experience), 1) as avg_years_experience
            """
        elif 'rate' in question.lower():
            # Obs≈Çuga 'Senior'
            role_filter = "WHERE p.rate IS NOT NULL"
            if "senior" in question.lower():
                role_filter = "WHERE toLower(p.seniority) CONTAINS 'senior' AND p.rate IS NOT NULL"
                
            cypher = f"""
            MATCH (p:Person)
            {role_filter}
            RETURN count(p) as count, round(avg(p.rate), 2) as avg_hourly_rate
            """
        elif 'total' in question.lower() and 'capacity' in question.lower():
             cypher = """
            MATCH (p:Person)
            OPTIONAL MATCH (p)-[r:ASSIGNED_TO]->()
            WITH p, sum(CASE WHEN r.allocation IS NOT NULL THEN r.allocation ELSE 0.0 END) as current_load
            RETURN 
                count(p) as total_developers,
                sum(CASE WHEN current_load = 0.0 THEN 1 ELSE 0 END) as fully_available,
                sum(CASE WHEN current_load > 0.0 AND current_load < 1.0 THEN 1 ELSE 0 END) as partially_available,
                sum(CASE WHEN current_load >= 1.0 THEN 1 ELSE 0 END) as fully_booked
            """
        else:
            cypher = """
            MATCH (p:Person)
            OPTIONAL MATCH (p)-[:HAS_SKILL]->(s:Skill)
            OPTIONAL MATCH (p)-[r:ASSIGNED_TO]->()
            WITH count(DISTINCT p) as dev_count, count(DISTINCT s) as skill_count, count(DISTINCT r) as assign_count
            RETURN dev_count as total_developers, skill_count as total_unique_skills, assign_count as total_assignments
            """

        try:
            result = self.graph.query(cypher)
            return {'type': 'aggregation', 'result': result[0] if result else {}, 'cypher': cypher, 'success': True}
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def handle_reasoning_query(self, question: str) -> Dict[str, Any]:
        print(f"üß† REASONING QUERY: {question}")
        
        # --- ZMIANA: Obs≈Çuga konkretnego imienia w pytaniu (Fix na Jacoba) ---
        target_person = ""
        if "Jacob Young" in question: target_person = "Jacob Young"
        elif "Robert Smith" in question: target_person = "Robert Smith"
        
        if target_person and ('worked together' in question.lower() or 'worked with' in question.lower()):
             cypher = f"""
             MATCH (p1:Person {{name: '{target_person}'}})-[:WORKED_AT]->(c:Company)<-[:WORKED_AT]-(p2:Person)
             WHERE p1.name <> p2.name
             RETURN p1.name as focus_person, p2.name as collaborator, c.name as context
             LIMIT 20
             """
        elif 'worked together' in question.lower():
             # Og√≥lne zapytanie (bez nazwiska w pytaniu)
             cypher = """
             MATCH (p1:Person)-[:WORKED_AT]->(c:Company)<-[:WORKED_AT]-(p2:Person)
             WHERE p1.name < p2.name
             RETURN p1.name as person_A, p2.name as person_B, c.name as shared_company
             LIMIT 10
             """
        elif 'same university' in question.lower():
            cypher = """
            MATCH (p1:Person)-[:STUDIED_AT]->(u:University)<-[:STUDIED_AT]-(p2:Person)
            WHERE p1.name < p2.name
            RETURN p1.name as developer_1, p2.name as developer_2, u.name as shared_university
            LIMIT 20
            """
        else:
            # Fallback
            cypher = "MATCH (n) RETURN n LIMIT 5"

        try:
            results = self.graph.query(cypher)
            return {'type': 'reasoning', 'result': results, 'cypher': cypher, 'success': True}
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def handle_temporal_query(self, question: str) -> Dict[str, Any]:
        print(f"‚è∞ TEMPORAL QUERY: {question}")

        # --- ZMIANA: Szukamy ludzi z sumƒÖ alokacji < 1.0 (Fix na dostƒôpno≈õƒá) ---
        if 'available' in question.lower() or 'free' in question.lower() or 'capacity' in question.lower():
            # U≈ºywamy CASE WHEN dla 100% pewno≈õci, ≈ºe Neo4j dobrze policzy
            cypher = """
            MATCH (p:Person)
            OPTIONAL MATCH (p)-[r:ASSIGNED_TO]->(:Project)
            WITH p, sum(CASE WHEN r.allocation IS NOT NULL THEN r.allocation ELSE 0.0 END) as load
            WHERE load < 1.0
            RETURN 
                p.name as name, 
                p.role as role, 
                round((1.0 - load) * 100, 0) as available_percent_capacity
            ORDER BY available_percent_capacity DESC
            LIMIT 20
            """
        
        # SCENARIUSZ B: "Becomes available" (Przysz≈Ço≈õƒá)
        elif 'after' in question.lower() or 'future' in question.lower() or 'becomes available' in question.lower():
            cypher = """
            MATCH (p:Person)-[r:ASSIGNED_TO]->(proj:Project)
            WHERE r.end_date IS NOT NULL 
            RETURN p.name as name, proj.name as current_project, r.end_date as available_from
            ORDER BY r.end_date ASC
            LIMIT 20
            """
        else:
            # Fallback to Capacity Logic
            cypher = """
            MATCH (p:Person)
            OPTIONAL MATCH (p)-[r:ASSIGNED_TO]->()
            WITH p, sum(CASE WHEN r.allocation IS NOT NULL THEN r.allocation ELSE 0.0 END) as load
            WHERE load < 1.0
            RETURN p.name, (1.0 - load) as capacity
            LIMIT 20
            """

        try:
            results = self.graph.query(cypher)
            # Je≈õli brak wynik√≥w, zwracamy pustƒÖ listƒô z sukcesem
            if not results:
                 return {'type': 'temporal', 'result': [], 'cypher': cypher, 'success': True}
            return {'type': 'temporal', 'result': results, 'cypher': cypher, 'success': True}
        except Exception as e:
            return {'success': False, 'error': str(e)}

    def handle_scenario_query(self, question: str) -> Dict[str, Any]:
        print(f"üéØ SCENARIO QUERY: {question}")
        
        # --- FIX: OBS≈ÅUGA SCENARIUSZA 6 (TEAM OPTIMIZATION) ---
        # Ten blok obs≈Çuguje z≈Ço≈ºonƒÖ logikƒô: Umiejƒôtno≈õci + Dostƒôpno≈õƒá + Limit
        if 'team' in question.lower() and ('optimal' in question.lower() or 'suggest' in question.lower()):
            
            # Prosta detekcja skilla (mo≈ºna rozbudowaƒá o LLM, ale to jest bezpieczniejsze)
            skill = "Python"
            if "Java" in question: skill = "Java"
            elif "AWS" in question: skill = "AWS"
            
            # Z≈Çote zapytanie: ≈ÅƒÖczy HAS_SKILL z logikƒÖ dostƒôpno≈õci (load < 1.0)
            cypher = f"""
            MATCH (p:Person)-[:HAS_SKILL]->(s:Skill)
            WHERE toLower(s.id) CONTAINS toLower('{skill}') OR toLower(s.name) CONTAINS toLower('{skill}')
            
            // Sprawd≈∫ dostƒôpno≈õƒá
            OPTIONAL MATCH (p)-[r:ASSIGNED_TO]->()
            WITH p, sum(CASE WHEN r.allocation IS NOT NULL THEN r.allocation ELSE 0.0 END) as load
            WHERE load < 1.0
            
            RETURN p.name as name, p.role as role, p.rate as rate, (1.0 - load)*100 as availability
            ORDER BY p.rate ASC  // Najta≈Ñsi pierwsi
            LIMIT 3
            """
            
            try:
                results = self.graph.query(cypher)
                return {'type': 'scenario', 'result': results, 'cypher': cypher, 'success': True}
            except Exception as e:
                return {'success': False, 'error': str(e)}
        
        # Fallback na standardowe filtrowanie, je≈õli to nie pytanie o zesp√≥≈Ç
        return self.handle_filtering_query(question)

    # ==================== NATURAL LANGUAGE GENERATION ====================

    def generate_natural_answer(self, question: str, data: Any) -> str:
        """Uses CREATIVE model to explain data to user (Privacy Aware)."""
        if not data:
            return "I searched the Knowledge Graph but found no matching records."
            
        prompt = f"""
        You are an HR Assistant. 
        User Question: "{question}"
        
        Data (from Database):
        {json.dumps(data)}
        
        Instructions:
        1. Answer based ONLY on the provided Data.
        2. The names in 'Data' might be masked (e.g. Candidate_X). USE THESE MASKED NAMES.
        3. **Do NOT speculate on identity mapping** (e.g. "If Candidate_X is Jacob Young..."). 
           Assume the data provided corresponds to the people asked about.
        4. Be professional and concise.
        """
        try:
            return self.llm_creative.invoke(prompt).content.strip()
        except Exception as e:
            return f"Data found, but summary failed. Raw data: {str(data)[:200]}..."

    # ==================== MAIN ENTRY POINT ====================

    def answer_question(self, question: str) -> Dict[str, Any]:
        """Main entry point: Classify -> Route -> Execute -> Anonymize -> Explain."""
        print(f"\nüìù Question: {question}")
        
        # 1. Klasyfikacja
        query_type = self.classify_query(question)
        print(f"üè∑Ô∏è  Type: {query_type}")

        # 2. Routing
        handlers = {
            'counting': self.handle_counting_query,
            'filtering': self.handle_filtering_query,
            'aggregation': self.handle_aggregation_query,
            'reasoning': self.handle_reasoning_query,
            'temporal': self.handle_temporal_query,
            'scenario': self.handle_scenario_query
        }
        
        handler = handlers.get(query_type, self.handle_scenario_query)
        result = handler(question)

        # 3. Privacy & Explanation
        if result.get('success'):
            raw_data = result.get('result')
            
            # --- PRIVACY STEP ---
            # Anonimizujemy dane ZANIM trafiƒÖ do LLM
            safe_data, decoder_map = self._anonymize_data(raw_data)
            
            natural_answer = self.generate_natural_answer(question, safe_data)
            result['natural_answer'] = natural_answer
            result['decoder_map'] = decoder_map # Przekazujemy klucz do szyfru dalej
            
            # Opcjonalnie: Dodajemy flagƒô
            result['privacy_compliant'] = True
            
        return result

    def format_result(self, result: Dict[str, Any]) -> str:
        """Format result for simple text output."""
        if not result.get('success'):
            return f"‚ùå Error: {result.get('error')}"
        if 'natural_answer' in result:
            return result['natural_answer']
        return str(result.get('result'))

# Test lokalny
if __name__ == "__main__":
    engine = BusinessIntelligenceEngine()
    print(engine.answer_question("Who becomes available after current project?"))