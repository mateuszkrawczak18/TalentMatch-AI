import sys
import os
import time
import random
from dotenv import load_dotenv

# --- MAGICZNY NAG≈Å√ìWEK ---
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.append(parent_dir)

# ≈Åadowanie .env
load_dotenv(os.path.join(parent_dir, ".env"))

from langchain_neo4j import Neo4jGraph

# Po≈ÇƒÖczenie z Neo4j
graph = Neo4jGraph(
    url=os.getenv("NEO4J_URI", "bolt://127.0.0.1:7687"),
    username=os.getenv("NEO4J_USERNAME", "neo4j"),
    password=os.getenv("NEO4J_PASSWORD", "password123")
)

def inject_dummy_data(target_count=600):
    print(f"\nüöÄ STRESS TEST: Scalability Check (Target: {target_count}+ nodes)")
    
    # 1. Sprawd≈∫ obecny stan
    try:
        current_count = graph.query("MATCH (p:Person) RETURN count(p) as c")[0]['c']
    except Exception as e:
        print(f"‚ùå Connection failed: {e}")
        return

    print(f"   üìä Current Database Size: {current_count} people")
    
    if current_count >= target_count:
        print("   ‚úÖ Requirement Met: Database already has > 500 profiles.")
        return

    needed = target_count - current_count
    print(f"   üíâ Injecting {needed} synthetic profiles (Cloning existing data)...")

    # 2. Masowe Klonowanie (Cypher Batch)
    # Klonujemy wƒôz≈Çy, dodajƒÖc losowy suffix do ID, ≈ºeby by≈Çy unikalne
    query = """
    MATCH (p:Person)-[:HAS_SKILL]->(s:Skill)
    WITH p, collect(s) as skills
    LIMIT 30  // Bierzemy wzorzec z pierwszych 30 prawdziwych CV
    
    UNWIND range(1, $multiplier) as i
    CREATE (new_p:Person)
    SET new_p = p
    SET new_p.id = p.id + '_Clone_' + toString(i) + '_' + toString(rand())
    SET new_p.name = p.name + ' (Clone ' + toString(i) + ')'
    SET new_p.is_synthetic = true
    
    FOREACH (skill in skills | 
        MERGE (sk:Skill {name: skill.name}) 
        MERGE (new_p)-[:HAS_SKILL]->(sk)
    )
    """
    
    # Obliczamy ile razy trzeba pomno≈ºyƒá te 30 os√≥b
    multiplier = (needed // 30) + 2
    
    print("   ‚è≥ Running batch insertion (this might take 10-20s)...")
    start_time = time.time()
    try:
        graph.query(query, {"multiplier": multiplier})
    except Exception as e:
        print(f"‚ùå Error during injection: {e}")
        return
        
    end_time = time.time()
    
    # Weryfikacja
    final_count = graph.query("MATCH (p:Person) RETURN count(p) as c")[0]['c']
    print(f"   ‚úÖ Injection Complete in {end_time - start_time:.2f}s")
    print(f"   üéâ Final Database Size: {final_count} people")

def benchmark_query_speed():
    print("\n‚è±Ô∏è PERFORMANCE CHECK: Database Latency")
    
    # Testujemy proste wyszukiwanie w du≈ºej bazie
    start = time.time()
    result = graph.query("""
        MATCH (p:Person)-[:HAS_SKILL]->(s:Skill)
        WHERE toLower(s.name) = 'python'
        RETURN count(p) as count
    """)
    end = time.time()
    duration = end - start
    
    count = result[0]['count']
    print(f"   üîç Query: Find all Python Developers in dataset of {count} people.")
    print(f"   ‚è±Ô∏è Execution Time: {duration:.4f} seconds")
    
    if duration < 0.1:
        print("   ‚úÖ RESULT: PASS (Database is blazing fast, < 0.1s)")
    elif duration < 2.0:
        print("   ‚úÖ RESULT: PASS (< 2.0s limit met)")
    else:
        print("   ‚ö†Ô∏è RESULT: SLOW (> 2.0s)")

if __name__ == "__main__":
    inject_dummy_data()
    benchmark_query_speed()