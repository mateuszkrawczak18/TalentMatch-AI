# TalentMatch AI - Complete Project Architecture & Technologies Guide

## ðŸ—ï¸ Project Overview

**TalentMatch AI** is an enterprise staffing intelligence system that uses **GraphRAG** (Graph-based Retrieval Augmented Generation) to intelligently match programmers to projects. It demonstrates how graph-based AI is superior to traditional vector-based RAG for structured business queries.

---

## ðŸ“Š Data Flow Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         INPUT SOURCES                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚   PDF CVs (30)   â”‚  â”‚   PDF RFPs (3)   â”‚  â”‚ Project Assign.  â”‚  â”‚
â”‚  â”‚  (Unstructured)  â”‚  â”‚  (Unstructured)  â”‚  â”‚    (YAML/JSON)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                    â”‚                   â”‚
            â–¼                    â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      PROCESSING ENGINES                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  FILE 1: 1_generate_data.py - DATA GENERATION               â”‚   â”‚
â”‚  â”‚  âœ“ Synthetic CV generation using LLM                        â”‚   â”‚
â”‚  â”‚  âœ“ RFP document creation                                    â”‚   â”‚
â”‚  â”‚  Output: 30 PDF CVs + 3 PDF RFPs                            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  FILE 2: 2_data_to_knowledge_graph.py - ETL PIPELINE        â”‚   â”‚
â”‚  â”‚  âœ“ PDF parsing (PyPDFLoader)                                â”‚   â”‚
â”‚  â”‚  âœ“ Entity extraction using LLM (LLMGraphTransformer)        â”‚   â”‚
â”‚  â”‚  âœ“ Relationship creation                                    â”‚   â”‚
â”‚  â”‚  Output: Neo4j Knowledge Graph (Nodes + Relationships)      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  FILE 3: 3_match_team.py - INTELLIGENT MATCHING ENGINE      â”‚   â”‚
â”‚  â”‚  âœ“ RFP parsing & requirement extraction                     â”‚   â”‚
â”‚  â”‚  âœ“ Multi-factor scoring algorithm                           â”‚   â”‚
â”‚  â”‚  âœ“ Real-time availability calculation                       â”‚   â”‚
â”‚  â”‚  Output: Ranked candidate recommendations + assignments     â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  FILE 4: 4_naive_rag_cv.py - TRADITIONAL RAG (BASELINE)     â”‚   â”‚
â”‚  â”‚  âœ“ Vector embeddings (ChromaDB)                             â”‚   â”‚
â”‚  â”‚  âœ“ Semantic search                                          â”‚   â”‚
â”‚  â”‚  Output: Text similarity-based results                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  FILE 5: 5_compare_systems.py - EVALUATION & COMPARISON     â”‚   â”‚
â”‚  â”‚  âœ“ Run both systems on same queries                         â”‚   â”‚
â”‚  â”‚  âœ“ Compare accuracy & performance                           â”‚   â”‚
â”‚  â”‚  Output: Comparison metrics & analysis                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â–¼                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  FILE 6: 6_business_intelligence.py - QUERY ENGINE (NEW)    â”‚   â”‚
â”‚  â”‚  âœ“ 6 query types (Counting, Filtering, Aggregation, etc)   â”‚   â”‚
â”‚  â”‚  âœ“ Cypher query generation & execution                      â”‚   â”‚
â”‚  â”‚  Output: Natural language answers to complex questions       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    DATABASE & STORAGE LAYER                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  Neo4j Graph Database (Docker)                              â”‚   â”‚
â”‚  â”‚  âœ“ Nodes: Person, Skill, Project, Company, Location        â”‚   â”‚
â”‚  â”‚  âœ“ Relationships: HAS_SKILL, ASSIGNED_TO, WORKED_AT, etc   â”‚   â”‚
â”‚  â”‚  âœ“ Port: 7474 (Browser), 7687 (Bolt protocol)              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  ChromaDB (Vector Store)                                    â”‚   â”‚
â”‚  â”‚  âœ“ Stores vector embeddings of CV documents                â”‚   â”‚
â”‚  â”‚  âœ“ For Naive RAG baseline comparison                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  File System                                                â”‚   â”‚
â”‚  â”‚  âœ“ data/cvs/ - Generated CV PDFs                           â”‚   â”‚
â”‚  â”‚  âœ“ data/rfps/ - Generated RFP PDFs                         â”‚   â”‚
â”‚  â”‚  âœ“ neo4j_data/ - Neo4j persistent volume                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“ File-by-File Breakdown

### **FILE 1: 1_generate_data.py** ðŸ”¨

**Purpose:** Generate realistic synthetic data to avoid using real employee data

| Aspect           | Details                                                                       |
| ---------------- | ----------------------------------------------------------------------------- |
| **What it does** | Creates 30 fake CVs and 3 RFP documents with plausible content                |
| **Key Classes**  | `GraphRAGDataGenerator`                                                       |
| **Technologies** | Faker (fake names), Azure OpenAI LLM, ReportLab (PDF generation)              |
| **Input**        | Configuration in `utils/config.toml`                                          |
| **Output**       | PDF files in `data/cvs/` and `data/rfps/`                                     |
| **Dependencies** | Faker, reportlab, langchain_openai                                            |
| **How it fits**  | **Step 1 of pipeline** - Creates realistic test data without privacy concerns |

**Key Methods:**

- `generate_cv_content()` - Uses LLM to write realistic CV text for fake developer
- `create_professional_pdf()` - Formats CV content into professional PDF
- `generate_rfps()` - Creates 3 sample project RFPs
- `generate_all_data()` - Orchestrates entire generation process

**Technology Stack Used:**

```
ðŸ¤– Azure OpenAI LLM
    â†“ (generates CV content)
ðŸ“ ReportLab
    â†“ (formats as PDF)
ðŸ“„ PDF Files (output)
```

---

### **FILE 2: 2_data_to_knowledge_graph.py** ðŸ§ 

**Purpose:** Transform unstructured PDF data into a queryable knowledge graph

| Aspect           | Details                                                                         |
| ---------------- | ------------------------------------------------------------------------------- |
| **What it does** | Reads PDFs, extracts entities/relationships, builds Neo4j graph                 |
| **Key Classes**  | None (functional approach with Neo4jGraph)                                      |
| **Technologies** | PyPDFLoader, LLMGraphTransformer, Neo4j, Azure OpenAI                           |
| **Input**        | PDF files from `data/cvs/`                                                      |
| **Output**       | Neo4j graph with nodes (Person, Skill, Company, etc)                            |
| **Dependencies** | langchain_community, langchain_neo4j, langchain_experimental                    |
| **How it fits**  | **Step 2 of pipeline** - Core GraphRAG engine that creates structured knowledge |

**Key Steps:**

1. **Connect to Neo4j** - Establish database connection
2. **Clear old data** - `MATCH (n) DETACH DELETE n` (fresh start)
3. **Initialize LLM** - Azure OpenAI for entity extraction
4. **Configure Transformer** - LLMGraphTransformer with allowed node types:
   - Person, Skill, Location, Company, University, Role
5. **Batch processing** - Process 5 pages at a time
6. **Store in Neo4j** - `graph.add_graph_documents()`

**Example Entity Extraction:**

```
Text: "John works as Python developer at Acme Inc in NYC"
        â†“ LLM processes
Entities:
  - Person(id="John")
  - Skill(id="Python")
  - Company(id="Acme Inc")
  - Location(id="NYC")
Relationships:
  - John -[:HAS_SKILL]-> Python
  - John -[:WORKED_AT]-> Acme Inc
  - John -[:LOCATED_IN]-> NYC
```

**Technology Stack Used:**

```
ðŸ“„ PDF Files
    â†“ (PyPDFLoader)
ðŸ“ Text Content
    â†“ (LLMGraphTransformer + Azure OpenAI)
ðŸ§  Entities & Relationships
    â†“ (graph.add_graph_documents)
ðŸ—„ï¸ Neo4j Database
```

**Graph Schema Created:**

```
NODES:
- Person {id, name, location}
- Skill {id, category}
- Company {id, name}
- Location {id, name}
- University {id, name}
- Project {id, name, required_skills}

RELATIONSHIPS:
- HAS_SKILL (Person -> Skill)
- WORKED_AT (Person -> Company)
- LOCATED_IN (Person/Company -> Location)
- STUDIED_AT (Person -> University)
- ASSIGNED_TO (Person -> Project)
```

---

### **FILE 3: 3_match_team.py** ðŸ‘¥

**Purpose:** Intelligently match developers to projects using multi-factor scoring

| Aspect           | Details                                                     |
| ---------------- | ----------------------------------------------------------- |
| **What it does** | Analyzes RFP requirements, scores developers, assigns teams |
| **Key Classes**  | `TeamMatcher`                                               |
| **Technologies** | PyPDFLoader, Azure OpenAI LLM, Neo4j (Cypher queries)       |
| **Input**        | PDF RFPs from `data/rfps/` + Neo4j graph                    |
| **Output**       | Team assignments + scored candidates                        |
| **Dependencies** | langchain_community, langchain_neo4j, langchain_openai      |
| **How it fits**  | **Step 3 of pipeline** - Business logic: matching algorithm |

**Key Methods:**

1. `analyze_rfp()` - Extracts requirements from RFP PDF using LLM

   - Required skills
   - Team size
   - Location preference
   - Budget/allocation

2. `find_and_assign_team()` - Two-stage matching algorithm:

   - **STAGE 1 (Strict Match):** Skills + Location + Availability
   - **STAGE 2 (Fallback):** Just availability (for gaps)
   - Scoring: `(skill_count Ã— 10) + location_score + (availability Ã— 20)`

3. `create_project_node()` - Creates Project node in Neo4j

**Matching Algorithm:**

```
Input: RFP with required skills [Python, AWS], team_size=5, location="NYC"

STAGE 1 - STRICT MATCH:
MATCH (p:Person)-[:HAS_SKILL]->(s:Skill)
WHERE s.id IN ['python', 'aws']
  AND (p)-[:LOCATED_IN]->(loc)
  AND loc.id CONTAINS 'NYC'
  AND (availability < 100%)
â†’ Returns: [Dev1(score=85), Dev2(score=72), Dev3(score=68)]

STAGE 2 - FALLBACK (if < 5 found):
MATCH (p:Person)  # No skills filter
WHERE (availability < 100%)
â†’ Returns: [Dev4(score=10), Dev5(score=10)]

OUTPUT:
âœ“ Dev1, Dev2, Dev3 (matched on skills)
âœ“ Dev4, Dev5 (filled gaps)
Assigned: Dev1 -[:ASSIGNED_TO]-> Project1
```

**Technology Stack Used:**

```
ðŸ“„ RFP PDF
    â†“ (PyPDFLoader + Azure LLM)
ðŸ“‹ Extracted Requirements
    â†“ (Cypher Queries)
ðŸ—„ï¸ Neo4j Graph
    â†“ (Scoring Algorithm)
ðŸ‘¥ Ranked Candidates
    â†“ (ASSIGNED_TO relationships)
âœ… Final Team Assignment
```

---

### **FILE 4: 4_naive_rag_cv.py** ðŸ“š

**Purpose:** Implement traditional vector-based RAG as a baseline comparison

| Aspect           | Details                                                               |
| ---------------- | --------------------------------------------------------------------- |
| **What it does** | Embeds CV text, creates vector search, answers questions semantically |
| **Key Classes**  | `NaiveRAGSystem`                                                      |
| **Technologies** | ChromaDB, Azure OpenAI Embeddings, RecursiveCharacterTextSplitter     |
| **Input**        | PDF CVs from `data/cvs/`                                              |
| **Output**       | Text results from semantic similarity search                          |
| **Dependencies** | langchain_chroma, langchain_openai, chromadb                          |
| **How it fits**  | **Alternative approach** - Demonstrates RAG limitations vs GraphRAG   |

**How it Works:**

```
Step 1: LOAD PDFs
  â†“
Step 2: CHUNK TEXT (RecursiveCharacterTextSplitter)
  PDF text â†’ chunks of ~500 chars
  â†“
Step 3: CREATE EMBEDDINGS (Azure OpenAI)
  Text chunk â†’ 1536-dim vector
  â†“
Step 4: STORE IN CHROMADB
  Vector index (in-memory or disk)
  â†“
Step 5: QUERY
  Question â†’ embedding â†’ cosine similarity search
  â†’ Top-K most similar chunks returned
```

**Limitations (why GraphRAG is better):**

```
Traditional RAG Problem:
Q: "How many Python developers are available?"
A: Returns text chunks mentioning "Python" and "available"
   But can't COUNT or aggregate properly
   (No understanding of structure)

GraphRAG Solution:
Q: Same question
A: Uses Cypher: MATCH (p)-[:HAS_SKILL]->(s:Skill)
                WHERE s.id='Python'
                RETURN count(p)
   Returns: 14 (precise answer)
```

**Technology Stack Used:**

```
ðŸ“„ PDF Files
    â†“ (PyPDFLoader + TextSplitter)
ðŸ“ Text Chunks
    â†“ (Azure OpenAI Embeddings)
ðŸ§® Vector Embeddings
    â†“ (ChromaDB)
ðŸ” Vector Index
    â†“ (Similarity Search)
ðŸ“‹ Top-K Similar Texts
```

---

### **FILE 5: 5_compare_systems.py** âš–ï¸

**Purpose:** Compare GraphRAG vs Naive RAG on same queries

| Aspect           | Details                                                         |
| ---------------- | --------------------------------------------------------------- |
| **What it does** | Runs both systems, measures accuracy/speed, reports differences |
| **Key Classes**  | None (orchestration script)                                     |
| **Technologies** | Dynamic imports, time measurement, results analysis             |
| **Input**        | Both systems initialized + test queries                         |
| **Output**       | Comparison metrics (accuracy, latency, correctness)             |
| **Dependencies** | 3_match_team.py, 4_naive_rag_cv.py                              |
| **How it fits**  | **Evaluation step** - Proves GraphRAG superiority               |

**What it Compares:**

```
Query Type: COUNTING
Q: "How many Python developers are available?"

GraphRAG:
- Time: 150ms
- Result: 14 (precise count)
- Accuracy: 100%

Naive RAG:
- Time: 200ms
- Result: "Found mentions of Python in 8 CVs" (text match)
- Accuracy: 50% (not actual count)
```

**Comparison Dimensions:**

- **Accuracy** - Correct vs incorrect answers
- **Latency** - Response time comparison
- **Query Complexity** - Simple vs complex (GraphRAG excels at complex)
- **Explainability** - Can show the Cypher query used

**Technology Stack Used:**

```
ðŸƒ Run GraphRAG (3_match_team.py)
    â†“ measure time
ðŸ’¾ Store Results
    â†“
ðŸƒ Run Naive RAG (4_naive_rag_cv.py)
    â†“ measure time
ðŸ’¾ Store Results
    â†“
ðŸ“Š Compare & Report
```

---

### **FILE 6: 6_business_intelligence.py** ðŸ¤– (NEW)

**Purpose:** Query engine for 6 types of complex business intelligence queries

| Aspect           | Details                                                                    |
| ---------------- | -------------------------------------------------------------------------- |
| **What it does** | Classifies questions, generates Cypher, executes in Neo4j, formats results |
| **Key Classes**  | `BusinessIntelligenceEngine`                                               |
| **Technologies** | Azure OpenAI (classification), Neo4j (Cypher), LangChain                   |
| **Input**        | Natural language questions                                                 |
| **Output**       | Structured answers with explanations                                       |
| **Dependencies** | langchain_neo4j, langchain_openai                                          |
| **How it fits**  | **Query interface** - Makes GraphRAG accessible via natural language       |

**6 Query Types Handled:**

```
1ï¸âƒ£ COUNTING QUERIES
   "How many Python developers are available?"
   Cypher: MATCH (p)-[:HAS_SKILL]->(s:Skill {id:'python'})
           WHERE available RETURN count(p)

2ï¸âƒ£ FILTERING QUERIES
   "Find developers with React experience"
   Cypher: MATCH (p)-[:HAS_SKILL]->(s:Skill {id:'react'})
           RETURN p.id, current_load

3ï¸âƒ£ AGGREGATION QUERIES
   "What's average experience for ML developers?"
   Cypher: MATCH (p)-[:ASSIGNED_TO]->(:Project)
           WHERE 'ML' IN project_skills
           RETURN avg(p.experience)

4ï¸âƒ£ REASONING QUERIES
   "Show developers who worked together"
   Cypher: MATCH (p1)-[:WORKED_AT]->(c)<-[:WORKED_AT]-(p2)
           WHERE p1 < p2
           RETURN p1, p2, c

5ï¸âƒ£ TEMPORAL QUERIES
   "Who becomes available after their projects end?"
   Cypher: MATCH (p)-[r:ASSIGNED_TO]->(proj)
           RETURN p.id, proj.end_date

6ï¸âƒ£ SCENARIO QUERIES
   "Optimal team for FinTech under budget?"
   Cypher: Complex multi-step reasoning with filters
```

**Architecture:**

```
Natural Language Input
    â†“
classify_query() [Azure LLM]
    â†“ (determines type)
Route to Handler
    â”œâ”€ handle_counting_query()
    â”œâ”€ handle_filtering_query()
    â”œâ”€ handle_aggregation_query()
    â”œâ”€ handle_reasoning_query()
    â”œâ”€ handle_temporal_query()
    â””â”€ handle_scenario_query()
    â†“
Generate Cypher
    â†“
Execute in Neo4j
    â†“
Format Results
    â†“
Return Answer
```

**Technology Stack Used:**

```
ðŸ¤– Azure OpenAI (Query Classification)
    â†“
ðŸ“‹ Cypher Query Templates
    â†“
ðŸ—„ï¸ Neo4j (Execution)
    â†“
ðŸ“Š Result Formatting
    â†“
âœ… Natural Language Answer
```

---

## ðŸ› ï¸ Infrastructure & Configuration

### **docker-compose.yml**

Runs Neo4j in Docker container

```yaml
Services:
- neo4j:5.11.0
  Ports: 7474 (Browser), 7687 (Bolt protocol)
  Auth: neo4j/password123
  Volume: ./neo4j_data (persistent storage)
  Plugins: apoc (for graph algorithms)
```

### **requirements.txt**

Python dependencies organized by purpose:

```
Core: LangChain framework
Graph: Neo4j integration
Vector: ChromaDB for embeddings
PDF: PyPDF, reportlab for documents
LLM: Azure OpenAI API
Utils: Faker, python-dotenv, toml
```

### **.env File**

Credentials and configuration:

```
AZURE_OPENAI_ENDPOINT=https://...
AZURE_OPENAI_API_KEY=...
AZURE_DEPLOYMENT_NAME=gpt-5-nano
NEO4J_URI=bolt://localhost:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=password123
```

---

## ðŸ”„ Complete Data Flow (End-to-End)

```
PHASE 1: DATA GENERATION
1_generate_data.py
  â†“ Creates: 30 synthetic CVs + 3 RFPs (PDFs)

PHASE 2: KNOWLEDGE GRAPH BUILDING
2_data_to_knowledge_graph.py
  â†“ Reads: PDFs
  â†“ Processes: LLMGraphTransformer (entity extraction)
  â†“ Stores: Neo4j (nodes + relationships)

PHASE 3: TEAM MATCHING
3_match_team.py
  â†“ Reads: RFP PDFs + Neo4j graph
  â†“ Analyzes: LLM extracts requirements
  â†“ Matches: Cypher queries with scoring
  â†“ Assigns: Creates ASSIGNED_TO relationships
  â†“ Output: Team recommendations

PHASE 4: BASELINE COMPARISON
4_naive_rag_cv.py
  â†“ Embeds: CV text into vectors (ChromaDB)
  â†“ Searches: Semantic similarity

5_compare_systems.py
  â†“ Compares: GraphRAG vs Naive RAG
  â†“ Reports: Accuracy, latency, quality

PHASE 5: BUSINESS INTELLIGENCE
6_business_intelligence.py
  â†“ Takes: Natural language questions
  â†“ Classifies: With Azure LLM
  â†“ Executes: Cypher queries in Neo4j
  â†“ Returns: Structured answers
```

---

## ðŸŽ¯ Key Technologies & Their Roles

| Technology              | Purpose                         | How it fits                                          |
| ----------------------- | ------------------------------- | ---------------------------------------------------- |
| **Azure OpenAI LLM**    | Text generation & understanding | Generates CVs, extracts entities, classifies queries |
| **Neo4j**               | Graph database                  | Stores knowledge graph, executed Cypher queries      |
| **LangChain**           | AI orchestration framework      | Connects components, manages chains                  |
| **LLMGraphTransformer** | Entity extraction               | Core of GraphRAG (unstructured â†’ structured)         |
| **ChromaDB**            | Vector database                 | Baseline RAG system for comparison                   |
| **PyPDFLoader**         | PDF parsing                     | Reads CV and RFP documents                           |
| **ReportLab**           | PDF generation                  | Creates synthetic CV documents                       |
| **Faker**               | Fake data generation            | Generates realistic names, etc                       |
| **Docker**              | Containerization                | Runs Neo4j consistently                              |
| **Python**              | Programming language            | Ties everything together                             |

---

## ðŸ’¡ How Components Interact

```
User Question
    â†“
6_business_intelligence.py
    â”œâ”€ Classifies with Azure LLM
    â””â”€ Routes to appropriate handler
    â†“
Handler (based on type)
    â”œâ”€ Generates Cypher query
    â””â”€ Executes via LangChain Neo4jGraph
    â†“
Neo4j Database
    â”œâ”€ Traverses graph
    â”œâ”€ Applies filters
    â””â”€ Returns results
    â†“
Business Intelligence Engine
    â”œâ”€ Formats results
    â””â”€ Explains findings
    â†“
User Answer (precise, explainable, structured)
```

---

## ðŸš€ Project Value Proposition

**Problem:** Traditional RAG (vector search) can't handle:

- Counting ("How many Python devs?")
- Filtering with AND/OR conditions
- Aggregations (averages, sums)
- Multi-hop reasoning (who worked together?)
- Complex business logic

**Solution:** GraphRAG via Neo4j

- Exact counts and aggregations âœ“
- Complex filtering âœ“
- Relationship reasoning âœ“
- Business intelligence queries âœ“

**Proof:** Files 4 & 5 demonstrate GraphRAG > Traditional RAG

---

## ðŸ“š File Dependencies & Execution Order

```
Prerequisite: docker-compose up -d  (start Neo4j)

1. 1_generate_data.py
   â””â”€ Creates data/cvs/*.pdf, data/rfps/*.pdf

2. 2_data_to_knowledge_graph.py
   â””â”€ Depends on: outputs from file 1
   â””â”€ Creates: Neo4j graph

3. 3_match_team.py
   â””â”€ Depends on: Neo4j graph from file 2
   â””â”€ Creates: Project nodes + assignments

4. 4_naive_rag_cv.py
   â””â”€ Depends on: data/cvs/*.pdf from file 1
   â””â”€ Creates: Vector embeddings

5. 5_compare_systems.py
   â””â”€ Depends on: files 3 & 4
   â””â”€ Creates: Comparison report

6. 6_business_intelligence.py
   â””â”€ Depends on: Neo4j graph from file 2
   â””â”€ Standalone: Can run after graph is built
```

---

## âœ¨ What's Next (For Completion)

To make the project fully functional for production:

1. **7_chatbot_streamlit.py** - Create UI for BI engine
2. **8_what_if_scenarios.py** - Simulation engine
3. **API layer** - REST endpoints for integration
4. **Documentation** - User guides, API specs
5. **Testing suite** - Unit & integration tests

---

Generated: 2025-12-31
